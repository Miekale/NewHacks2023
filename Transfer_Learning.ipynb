{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import pandas as pd\n",
    "import os\n",
    "from torchvision.io import read_image\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "from torchvision.transforms import transforms\n",
    "from typing import Iterator\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import time\n",
    "import copy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants\n",
    "img_dir = r\"C:\\Users\\Humperdink2\\Documents\\github\\NewHacks2023\\Food Images\\Food Images\"\n",
    "data_dir = r\"C:\\Users\\Humperdink2\\Documents\\github\\NewHacks2023\\Food Ingredients and Recipe Dataset with Image Name Mapping.csv\"\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "img_size = 169\n",
    "output_size = 13470"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler(RandomSampler):\n",
    "    #removes bad values\n",
    "    \n",
    "    def __init__(self, data_source, forbidden = []) -> None:\n",
    "        super().__init__(data_source)\n",
    "        self.data_source = data_source\n",
    "        self.forbidden = forbidden\n",
    "        self.refill()\n",
    "\n",
    "    def remove(self, new_forbidden):\n",
    "        # Remove numbers from the available indices\n",
    "        for num in new_forbidden:\n",
    "            if not (num in self.forbidden):\n",
    "                self.forbidden.append(num)\n",
    "        self._remove(new_forbidden)\n",
    "\n",
    "    def _remove(self, to_remove):\n",
    "        # Remove numbers just for this epoch\n",
    "        for num in to_remove:\n",
    "            if num in self.idx:\n",
    "                self.idx.remove(num)\n",
    "\n",
    "        self._num_samples = len(self.idx)\n",
    "\n",
    "    def refill(self):\n",
    "        # Refill the indices after iterating through the entire DataLoader\n",
    "        self.idx = list(range(len(self.data_source)))\n",
    "        self._remove(self.forbidden)\n",
    "\n",
    "    def __iter__(self) -> Iterator[int]:\n",
    "        for _ in range(self.num_samples // 32):\n",
    "            batch = random.sample(self.idx, 32)\n",
    "            self._remove(batch)\n",
    "            yield from batch\n",
    "        yield from random.sample(self.idx, self.num_samples % 32)\n",
    "        self.refill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constructing the dataloader\n",
    "class foodImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, data_dir, transformation = None):\n",
    "        self.img_dir = img_dir\n",
    "        self.ingr = pd.read_csv(data_dir, header=1,usecols=[5])\n",
    "        self.transform = transformation\n",
    "        self.labels = pd.read_csv(data_dir, header=1,usecols=[0,4])\n",
    "\n",
    "    #Later augment the dataset to give more images per class to increase accuracy\n",
    "\n",
    "    def __len__(self):\n",
    "       return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.labels.iloc[idx,1] + \".jpeg\")\n",
    "        try:\n",
    "            image = read_image(img_path)\n",
    "        except:\n",
    "            f\"file not found {img_path}\"\n",
    "            return None\n",
    "        label = self.labels.iloc[idx, 0]\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "    def __getingrs__(self, index):\n",
    "        return self.ingr.iloc[index,0]\n",
    "    \n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((169,169)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "food = foodImageDataset(img_dir, data_dir, transformation=transform)\n",
    "food_dl = DataLoader(food, batch_size, shuffle=True)\n",
    "\n",
    "# for i in range(len(food)):\n",
    "#     sample = food[i]\n",
    "#     if food[i] is  None:\n",
    "#         print(i)\n",
    "#         # print(i,sample['image'].shape, sample[\"label\"], sample[\"ingr\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Target 11776 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Humperdink2\\Documents\\github\\NewHacks2023\\TrAnfErLeaRning.ipynb Cell 5\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Humperdink2/Documents/github/NewHacks2023/TrAnfErLeaRning.ipynb#W3sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     model\u001b[39m.\u001b[39mload_state_dict(best_model_wts)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Humperdink2/Documents/github/NewHacks2023/TrAnfErLeaRning.ipynb#W3sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Humperdink2/Documents/github/NewHacks2023/TrAnfErLeaRning.ipynb#W3sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m model_ft \u001b[39m=\u001b[39m train_model(food_dl, model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Humperdink2/Documents/github/NewHacks2023/TrAnfErLeaRning.ipynb#W3sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m                        num_epochs\u001b[39m=\u001b[39;49m\u001b[39m25\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\Humperdink2\\Documents\\github\\NewHacks2023\\TrAnfErLeaRning.ipynb Cell 5\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Humperdink2/Documents/github/NewHacks2023/TrAnfErLeaRning.ipynb#W3sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Humperdink2/Documents/github/NewHacks2023/TrAnfErLeaRning.ipynb#W3sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m _, preds \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(outputs, \u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Humperdink2/Documents/github/NewHacks2023/TrAnfErLeaRning.ipynb#W3sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Humperdink2/Documents/github/NewHacks2023/TrAnfErLeaRning.ipynb#W3sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m# backward + optimize only if in training phase\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Humperdink2/Documents/github/NewHacks2023/TrAnfErLeaRning.ipynb#W3sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39mif\u001b[39;00m phase \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Humperdink2\\anaconda3\\envs\\newhacks\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Humperdink2\\anaconda3\\envs\\newhacks\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Humperdink2\\anaconda3\\envs\\newhacks\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1179\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m-> 1179\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mcross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[0;32m   1180\u001b[0m                            ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction,\n\u001b[0;32m   1181\u001b[0m                            label_smoothing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_smoothing)\n",
      "File \u001b[1;32mc:\\Users\\Humperdink2\\anaconda3\\envs\\newhacks\\lib\\site-packages\\torch\\nn\\functional.py:3053\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3051\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3052\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3053\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[1;31mIndexError\u001b[0m: Target 11776 is out of bounds."
     ]
    }
   ],
   "source": [
    "device = torch.cuda.set_device(0)\n",
    "model_ft = models.vgg16(pretrained=True)\n",
    "\n",
    "classifier = model_ft.classifier\n",
    "num_ftrs = classifier[0].in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, output_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "optimizer_ft = torch.optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "\n",
    "def train_model(trainloader,model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in trainloader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "            # deep copy the model\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "model_ft = train_model(food_dl, model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newhacks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

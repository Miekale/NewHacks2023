{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import pandas as pd\n",
    "import os\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants\n",
    "img_dir = r\"C:\\Users\\Humperdink2\\Documents\\github\\NewHacks2023\\Food Images\"\n",
    "data_dir = r\"C:\\Users\\Humperdink2\\Documents\\github\\NewHacks2023\\Food Ingredients and Recipe Dataset with Image Name Mapping.csv\"\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "img_size = 169"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processing Dataset:\n",
    "def getData(img_dir, data_dir):\n",
    "    \"\"\"\n",
    "    Inputs: Image folder directory\n",
    "            CSV containing labels directory\n",
    "\n",
    "    Returns: List of labels\n",
    "             List of image file names\n",
    "             List of ingredients per recipe\n",
    "             Number of non-corrupted images in data\n",
    "\n",
    "    \"\"\"\n",
    "    labels = pd.read_csv(data_dir,usecols=[1,4,5])\n",
    "\n",
    "    count = 0 \n",
    "    for label in labels.iterrows():\n",
    "        if count % 1000 == 0:\n",
    "            print(f\"The count is {count}\")\n",
    "        img_path = os.path.join(img_dir, labels.iat[count,1] + \".jpg\")\n",
    "        try:\n",
    "            image=read_image(img_path)\n",
    "            if image == None:\n",
    "                print(count)\n",
    "                labels = labels.drop(labels.index[count])\n",
    "                continue\n",
    "            count += 1\n",
    "        except:\n",
    "            print(count)\n",
    "            labels = labels.drop(labels.index[count])\n",
    "    labels.reset_index(drop=True, inplace=True)\n",
    "    return labels.iloc[:,0], labels.iloc[:,1], labels.iloc[:,2], count\n",
    "\n",
    "# constructing the dataloader\n",
    "class foodImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, labels, file_names, ingr, transformation = None):\n",
    "        self.img_dir = img_dir\n",
    "        self.ingr = ingr\n",
    "        self.transform = transformation\n",
    "        self.labels = labels\n",
    "        self.file_names = file_names\n",
    "    \"\"\" \n",
    "    TO ALTER ADD DATA AUGMENTATION TO THE MODEL\n",
    "    \"\"\"\n",
    "    def __len__(self):\n",
    "       return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.file_names[idx] + \".jpg\")\n",
    "\n",
    "        #Grabbing and closing image\n",
    "        image = None\n",
    "        with Image.open(img_path).convert(\"RGB\") as temp:\n",
    "            image = temp\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "    def __getingrs__(self, index):\n",
    "        return self.ingr[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, file_names, ingr, output_size  = getData(img_dir,data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding labels\n",
    "le = LabelEncoder()\n",
    "targets = le.fit_transform(labels)\n",
    "targets = torch.as_tensor(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Declaration\n",
    "class FoodModel(nn.Module):\n",
    "    def __init__(self,img_size, output_size):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            #3x169x169\n",
    "            nn.Conv2d(3,32,kernel_size=(3,3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2,2)),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            #32x84x84\n",
    "            nn.Conv2d(32,16,kernel_size=(3,3), padding=1),\n",
    "            nn.MaxPool2d(kernel_size=(2,2)),\n",
    "\n",
    "            #16x42x42\n",
    "            nn.Conv2d(16,8,kernel_size=(3,3), padding=1),\n",
    "            nn.MaxPool2d(kernel_size=(2,2)),\n",
    "\n",
    "            #8x21*21\n",
    "            nn.Flatten(),\n",
    "\n",
    "            #1x(8*21*21)\n",
    "            nn.Linear(8*21*21, int(output_size*2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(.5),\n",
    "            \n",
    "            #1*2700\n",
    "            nn.Linear(output_size*2, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, image):\n",
    "        image = self.model(image)\n",
    "        return image\n",
    "    \n",
    "    def train(self, epochs, train_dl, loss_fn, opt):\n",
    "        for epoch in range(epochs):\n",
    "            for image, labels in train_dl:\n",
    "                labels = labels.to(torch.long)\n",
    "                preds = self(image)\n",
    "                print(type(labels))\n",
    "                loss = loss_fn(preds, labels)\n",
    "                #training\n",
    "                opt.zero_grad()\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "            print(f\"epoch {epoch} Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sending to GPU\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "def to_device(data, device):\n",
    "    #Move tensor(s) to chosen device\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    def __init__(self, dl, device):\n",
    "        self.device = device\n",
    "        self.dl = dl\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for b in self.dl:\n",
    "            #generating iterater of batches\n",
    "            yield to_device(b,self.device)\n",
    "    \n",
    "    def __len__(self):\n",
    "        #num batches\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_device()\n",
    "model = FoodModel(img_size, output_size)\n",
    "model = to_device(model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting Model\n",
    "opt = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((169,169)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "food = foodImageDataset(img_dir, targets, file_names, ingr, transformation=transform)\n",
    "food_dl = DataLoader(food, batch_size, shuffle=True)\n",
    "food_dl = DeviceDataLoader(food_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running Model\n",
    "model.train(5,food_dl,loss_fn,opt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newhacks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
